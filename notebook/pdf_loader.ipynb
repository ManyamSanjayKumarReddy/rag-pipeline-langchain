{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83cc740a",
   "metadata": {},
   "source": [
    "\n",
    "RAG Pipeline- Date Injestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1bbffa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81d3e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "processing: Manual for Skill registry - Industry Registration and Login.pdf\n",
      "Loaded 17 pages\n",
      "\n",
      "processing: MANYAM-SANJAY-KUMAR-REDDY.pdf\n",
      "Loaded 3 pages\n",
      "Total Documents Loaded: 20\n"
     ]
    }
   ],
   "source": [
    "## read all the pdfs inside the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all the pdf files from the directory\"\"\"\n",
    "\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # find all pdf files recursivley\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nprocessing: {pdf_file.name}\")\n",
    "\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # add source info to meta data\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "\n",
    "            print(f\"Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "    \n",
    "    print(f\"Total Documents Loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# process all the pdf documents from the directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b602de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_pdf_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0878216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitting into Chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split the documents into smaller chunks for better rag performance\"\"\"\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = len,\n",
    "        separators=[\"\\n\\n\",\"\\n\",\" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # sample chunk\n",
    "    if split_docs:\n",
    "        print(\"\\nExample Chunk: \")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f8ca5224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 20 documents into 26 chunks\n",
      "\n",
      "Example Chunk: \n",
      "Content: Key Features of TNSKILL Registry \n",
      "1. Simple Registration & Login \n",
      " \n",
      "Register using Company / Industry details with admin approval \n",
      "process. \n",
      " \n",
      "Multiple login methods: Email/Password, Mobile/Password...\n",
      "metadata: {'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-09-23T09:29:52+00:00', 'source': '../data/Manual for Skill registry - Industry Registration and Login.pdf', 'file_path': '../data/Manual for Skill registry - Industry Registration and Login.pdf', 'total_pages': 17, 'format': 'PDF 1.5', 'title': '', 'author': 'AVP-Portal Naanmudhalvan', 'subject': '', 'keywords': '', 'moddate': '2025-09-23T09:29:52+00:00', 'trapped': '', 'modDate': 'D:20250923092952Z', 'creationDate': \"D:20250923092952+00'00'\", 'page': 0, 'source_file': 'Manual for Skill registry - Industry Registration and Login.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a421a7d",
   "metadata": {},
   "source": [
    "### embeddings and vectorStore DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2037179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Dict,Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8e70713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOading embedding model: all-MiniLM-L6-v2\n",
      "Model Loaded Successfully. Embedded Dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x7104956a75f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using sentence transformer\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "\n",
    "        Initilze the embedding manager\n",
    "\n",
    "        Args:\n",
    "            model_name : Huggingface model name for sentence embeddings\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentence transformer model\"\"\"\n",
    "\n",
    "        try:\n",
    "            print(f\"LOading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "\n",
    "            print(f\"Model Loaded Successfully. Embedded Dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error loading model {self.model_name}:  {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self,texts:List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate Embeddings for a list of texts\n",
    "\n",
    "        Args:\n",
    "            texts: List of text strings to embbed\n",
    "        \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not LOaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "    ## initilize the embedding maanger\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc1cf306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store initilized. Collection : pdf_documents\n",
      "Exisiting documents in collection 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x7104956ae420>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Store\n",
    "\n",
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in chromadb vector store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../chromadb/vector_store\"):\n",
    "        \"\"\"\n",
    "\n",
    "        Initilize the vector store\n",
    "\n",
    "        Args:\n",
    "            collection_name : Name of the chromadb collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initilize_store()\n",
    "\n",
    "    def _initilize_store(self):\n",
    "        \"\"\"Initilize chromadb client and collection\"\"\"\n",
    "        try:\n",
    "            # create persistant chromadb client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata = {\"description\": \"PDF Document embeddings for RAG\"}\n",
    "            )\n",
    "\n",
    "            print(f\"vector store initilized. Collection : {self.collection_name}\")\n",
    "            print(f\"Exisiting documents in collection {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERror initilizing vector store {e}\")\n",
    "            raise\n",
    "    \n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add Documents and their embeddings to the vector store \n",
    "\n",
    "        Args:\n",
    "            document:List of Langchain documents\n",
    "            embeddings: corrosponding embeddings of the document\n",
    "        \"\"\"\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"number of documents should match the embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store\")\n",
    "\n",
    "        # prepare data for chromaDB\n",
    "\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list  = []\n",
    "\n",
    "        for i , (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "\n",
    "            # create unique id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # prepare meta data\n",
    "\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document Content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # embeddings\n",
    "\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # add to collections\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings= embeddings_list,\n",
    "                metadatas = metadatas,\n",
    "                documents= documents_text\n",
    "            )\n",
    "\n",
    "            print(f\"successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")    \n",
    "        except Exception as e:\n",
    "            print(f\"ERror adding documents to vector store\") \n",
    "            raise   \n",
    "        \n",
    "vectorstore = VectorStore()\n",
    "vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70f13e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8317579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 26 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (26, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate the embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "242a5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 26 documents to vector store\n",
      "successfully added 26 documents to vector store\n",
      "Total documents in collection: 26\n"
     ]
    }
   ],
   "source": [
    "# store in the vector store\n",
    "vectorstore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "28faed0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1711098e-01, -8.3010029e-03, -1.3160699e-02, ...,\n",
       "         5.8422845e-02, -3.0940678e-04, -1.5282723e-02],\n",
       "       [-3.0139044e-02,  4.5634367e-02,  3.8228072e-02, ...,\n",
       "         3.5444930e-02, -2.0149043e-02,  8.9973792e-02],\n",
       "       [-6.6491023e-02,  3.0301595e-03, -7.2023220e-02, ...,\n",
       "         6.3133039e-02,  2.4088241e-02, -3.3927321e-02],\n",
       "       ...,\n",
       "       [-1.4644398e-01,  6.7608147e-05, -2.7036730e-02, ...,\n",
       "        -3.2940016e-03, -1.2926569e-02,  2.4265300e-02],\n",
       "       [-1.4477530e-01, -6.7603953e-02,  7.5297724e-03, ...,\n",
       "        -5.3227521e-02, -3.9992481e-02,  6.2061094e-02],\n",
       "       [-8.5309140e-02,  6.2356364e-02,  1.2115482e-02, ...,\n",
       "        -6.6514254e-02, -2.1456851e-02,  6.7950841e-03]],\n",
       "      shape=(26, 384), dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full content of the doc page content\n",
    "# texts \n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b95afdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ec90fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: \n",
      "You can view Skilled professional details such as: \n",
      " \n",
      "Candidate Name \n",
      " \n",
      "Skills & Qualifications \n",
      " \n",
      "Location \n",
      " \n",
      "Experience \n",
      " \n",
      "Naan Mudhalvan Certification Details \n",
      " \n",
      "Resume \n",
      " \n",
      "Current Status \n",
      " \n",
      "Profile \n",
      " \n",
      "Year of Passing \n",
      " \n",
      "District, etc. \n",
      "To further shortlist candidates, you can use the filters in the left pane, such as: \n",
      " \n",
      "Gender \n",
      " \n",
      "Year of Passing \n",
      " \n",
      "College Type \n",
      " \n",
      "District, etc.\n",
      "Step 4: \n",
      "You can view Skilled professional details such as: \n",
      " \n",
      "Candidate Name \n",
      " \n",
      "Skills & Qualifications \n",
      " \n",
      "Location \n",
      " \n",
      "Experience \n",
      " \n",
      "Naan Mudhalvan Certification Details \n",
      " \n",
      "Resume \n",
      " \n",
      "Current Status \n",
      " \n",
      "Profile \n",
      " \n",
      "Year of Passing \n",
      " \n",
      "District, etc. \n",
      "To further shortlist candidates, you can use the filters in the left pane, such as: \n",
      " \n",
      "Gender \n",
      " \n",
      "Year of Passing \n",
      " \n",
      "College Type \n",
      " \n",
      "District, etc.\n",
      "[-1.57551828e-03  4.77492511e-02  3.82212293e-03  1.07069314e-02\n",
      " -2.38509523e-03  4.70534675e-02 -3.81530933e-02 -6.97295442e-02\n",
      " -1.42953724e-01 -7.32311904e-02 -4.76059802e-02 -1.39208108e-01\n",
      "  3.22345411e-03  1.93847772e-02 -5.86917661e-02 -5.82079589e-02\n",
      " -4.60173525e-02  6.45139813e-02  4.18674350e-02 -1.01138078e-01\n",
      "  5.39890490e-02  3.43884118e-02  4.78882948e-03 -8.92270952e-02\n",
      " -5.01041189e-02 -5.45007698e-02  6.35793284e-02 -2.15904359e-02\n",
      " -3.05433087e-02 -1.16453478e-02  5.34147173e-02  2.13005133e-02\n",
      "  2.23478880e-02  4.06252705e-02  6.13649674e-02 -2.53657494e-02\n",
      " -7.13873729e-02  1.34745389e-01  5.81639037e-02  7.77254300e-03\n",
      " -2.25348976e-02 -9.23541337e-02 -3.45859192e-02 -2.85207983e-02\n",
      " -5.15641936e-04 -3.89469787e-02 -2.02066079e-02 -8.76464099e-02\n",
      "  2.20252220e-02  5.14791720e-02 -8.82588178e-02 -6.95250975e-03\n",
      "  2.17789151e-02 -1.23986928e-02  2.84987055e-02 -5.68617252e-04\n",
      " -1.05391219e-01 -3.23684290e-02 -9.15651917e-02  1.86282359e-02\n",
      "  1.07715353e-02  1.41788227e-02 -1.07458577e-01  1.05247833e-02\n",
      " -2.83505861e-02  3.51153202e-02 -1.52963847e-02  5.93976229e-02\n",
      "  5.59848920e-02 -5.55082187e-02 -8.62707011e-03 -1.08938152e-02\n",
      " -7.70954341e-02 -2.26909830e-03  2.64466573e-02 -3.92419063e-02\n",
      "  4.47959974e-02  6.96928352e-02 -1.78404208e-02 -6.06720895e-02\n",
      " -3.53535563e-02 -1.21980906e-02  1.23253502e-02  3.77938934e-02\n",
      "  5.06790504e-02  1.67584512e-02  3.78362425e-02 -5.96402399e-02\n",
      " -3.78694907e-02 -1.45763671e-02  9.94606689e-02 -4.09214422e-02\n",
      " -2.06831619e-02 -1.67062487e-02  1.14932107e-02 -4.94982153e-02\n",
      "  3.35876569e-02  3.79872583e-02  7.13397637e-02  5.74808232e-02\n",
      " -9.17671919e-02 -8.83475021e-02 -4.05812114e-02  8.12382437e-03\n",
      " -1.13158301e-01 -2.02723220e-02  5.73634058e-02 -3.35039459e-02\n",
      " -3.67968380e-02  4.47500311e-02  3.32528949e-02  6.11670688e-02\n",
      " -9.16097686e-02 -1.70504432e-02  6.78962469e-02  4.48347554e-02\n",
      " -7.79696330e-02  2.74731796e-02 -2.05205791e-02  2.38031428e-02\n",
      " -9.37708020e-02  2.05177180e-02 -4.23588417e-02 -3.58688086e-02\n",
      "  4.83791493e-02  4.07378674e-02 -2.81431917e-02  3.55900163e-33\n",
      "  3.08510046e-02  5.16782776e-02 -5.19611500e-02  3.55068706e-02\n",
      " -4.95635644e-02  8.97973590e-03  5.57284243e-02 -1.68160684e-02\n",
      "  4.16800082e-02  3.98032274e-03  2.59261820e-02  3.70980650e-02\n",
      " -5.51916733e-02 -1.84106606e-03 -5.31975813e-02  7.32297152e-02\n",
      " -4.12551053e-02 -1.36459433e-03 -1.18872941e-01  5.68170063e-02\n",
      " -2.22935632e-04  1.27670029e-02 -3.22859325e-02  1.27442274e-02\n",
      "  6.44655600e-02  3.38435955e-02  3.70118506e-02  3.46927419e-02\n",
      " -2.28342321e-02  3.36462446e-02  4.28528376e-02 -4.60679866e-02\n",
      "  1.33456895e-02 -5.12944721e-02  9.26403925e-02  1.43865868e-01\n",
      "  3.30730081e-02 -5.40545397e-03  5.70116229e-02 -3.70785743e-02\n",
      " -1.15485173e-02 -2.18100753e-02 -6.93579717e-03  5.88949434e-02\n",
      " -8.01737383e-02 -2.06994414e-02  6.79824734e-04  5.44595830e-02\n",
      "  9.51049328e-02  8.65977928e-02  3.27287235e-05 -6.98855054e-03\n",
      " -9.35290605e-02 -5.02516367e-02 -2.41003949e-02 -1.09047638e-02\n",
      " -3.85550968e-02  1.57934558e-02  2.57266108e-02  3.12755890e-02\n",
      "  6.70220610e-03 -5.18256426e-03 -1.11038290e-01 -8.66445992e-03\n",
      " -3.07792071e-02 -5.71743362e-02 -1.46656181e-03 -3.86024974e-02\n",
      "  1.62997752e-01 -1.29776284e-01 -4.19742763e-02 -8.38461798e-03\n",
      "  5.15971854e-02  5.95164187e-02 -5.37018944e-03  5.44297807e-02\n",
      " -1.10098692e-02 -2.61570290e-02 -1.33148450e-02  3.78535204e-02\n",
      "  1.25994189e-02  1.85309816e-02 -4.01404500e-02  2.56672734e-03\n",
      "  8.24210569e-02 -3.36867347e-02  5.99397272e-02 -5.02662100e-02\n",
      "  2.27286965e-02  5.27999084e-03  1.79943182e-02  3.22516151e-02\n",
      " -4.02298197e-02  5.80233149e-03  2.69819666e-02 -4.27228352e-33\n",
      "  8.46453905e-02 -3.56011838e-02 -2.46100072e-02 -2.04686504e-02\n",
      "  7.74560198e-02  7.90950609e-04  1.07966855e-01  2.31886581e-02\n",
      "  2.35657617e-02 -1.67829394e-02  8.28882456e-02 -2.22005579e-03\n",
      " -5.38216578e-03 -2.38097850e-02 -4.41654660e-02 -1.88663062e-02\n",
      " -9.07819644e-02  5.76769598e-02  3.26095000e-02  2.16645766e-02\n",
      " -1.49888301e-03  5.46646528e-02 -6.09688722e-02  7.00161792e-03\n",
      " -2.70766318e-02  8.78418237e-03  3.18806395e-02 -2.92549673e-02\n",
      " -3.44191305e-03  2.94852369e-02  2.35506296e-02 -6.65663406e-02\n",
      " -8.47422332e-02  5.54584637e-02 -5.87136969e-02 -5.06066456e-02\n",
      " -1.13199344e-02 -3.34912166e-02  1.13710631e-02  1.35970980e-01\n",
      "  1.61487460e-02 -2.76542772e-02 -3.27617973e-02 -4.61275864e-04\n",
      " -2.00330131e-02 -4.01635244e-02  2.19526719e-02  3.62591967e-02\n",
      "  7.78043643e-03 -5.05200699e-02  6.89471588e-02  3.27656828e-02\n",
      "  8.96200817e-03 -8.19175225e-03  8.21740329e-02  4.00688760e-02\n",
      "  5.73012158e-02 -7.17982799e-02  6.94731846e-02  6.18455559e-02\n",
      " -1.88166127e-02  1.48302764e-02  8.86298995e-03  7.23148417e-03\n",
      "  4.72147241e-02 -1.13862760e-01  5.40502951e-04 -9.08029638e-03\n",
      " -6.70698807e-02 -2.80713439e-02 -5.02466112e-02 -1.15217231e-01\n",
      "  4.93515879e-02 -5.04964106e-02 -1.03016451e-01 -5.94183281e-02\n",
      " -5.69182038e-02  7.41388425e-02  3.18892859e-02  2.24384200e-02\n",
      " -2.09180173e-03 -3.27675277e-03 -4.45364006e-02 -1.22940987e-02\n",
      "  4.12563570e-02  9.33903828e-02  4.18319404e-02 -5.53163625e-02\n",
      "  7.88202435e-02 -5.50341234e-02 -2.80132191e-03 -1.98611487e-02\n",
      " -4.30588573e-02 -3.75210457e-02 -6.59198388e-02 -3.53750131e-08\n",
      "  1.91979352e-02 -2.14679129e-02 -3.05509977e-02  1.70764271e-02\n",
      "  1.93845630e-02  6.52652457e-02 -2.39949711e-02  8.83524343e-02\n",
      " -3.38817239e-02  5.33579327e-02  6.60466179e-02  2.18794704e-03\n",
      " -7.22526684e-02 -1.93605162e-02  7.42067397e-02  4.00981382e-02\n",
      "  4.92164642e-02  1.50880113e-01 -1.95320770e-02 -1.05332304e-02\n",
      "  1.53451040e-02  2.94513442e-02 -7.90233612e-02  8.07465091e-02\n",
      "  5.82409278e-03  1.17107304e-02 -6.27652407e-02  4.08482701e-02\n",
      " -4.43166420e-02 -2.60390136e-02 -8.67730379e-03  5.25643528e-02\n",
      "  1.04288213e-01 -7.99665824e-02  5.31089790e-02  3.60531248e-02\n",
      " -1.31019764e-02  2.20297929e-02  4.60242070e-02  2.33959239e-02\n",
      " -2.83809360e-02  1.03075337e-02  2.29690392e-02  2.13224087e-02\n",
      "  1.17518231e-02  2.01174468e-02  6.26589125e-03 -4.25384492e-02\n",
      " -1.17680607e-02  4.15923595e-02 -2.37158462e-02 -7.52059221e-02\n",
      "  6.87347054e-02 -2.57588010e-02 -6.59823939e-02  7.10664168e-02\n",
      " -2.22123079e-02 -4.01255116e-03 -2.42936239e-02 -2.07366757e-02\n",
      "  4.21603918e-02  5.54263294e-02 -4.07133885e-02  6.76382482e-02]\n"
     ]
    }
   ],
   "source": [
    "print(chunks[11].page_content)\n",
    "print(texts[11])\n",
    "print(embeddings[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2c3d3ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x71043a2ab5c0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles Query based retrieval from vector store\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "\n",
    "        Initilize the retrivever\n",
    "\n",
    "        Args:\n",
    "            vector_store: Vector Store containing document Embeddings\n",
    "            embeddings_manager : Manager for generating query embeddings\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "\n",
    "        Retrieve the relevant elements for a query\n",
    "\n",
    "        Args:\n",
    "            query : the search query\n",
    "            top_k : NUmber of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "         \n",
    "        Returns:\n",
    "            List of Dictionaries containing retrived documents and metadatas\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Retrieving documents for the '{query}'\")\n",
    "        print(f\"Top K : {top_k}, score threshold : {score_threshold}\")\n",
    "\n",
    "        # generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        # search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings = [query_embedding.tolist()],\n",
    "                n_results = top_k\n",
    "            )\n",
    "\n",
    "            # processed results\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids=results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # convery distance to similary score (chromadb uses cosine distance)\n",
    "\n",
    "                    similrity_score = 1 - distance\n",
    "\n",
    "                    if similrity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similrity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1 \n",
    "                        })\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filetring)\")\n",
    "\n",
    "            else:\n",
    "                print(\"NO Documents Found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "            \n",
    "rag_retriever = RAGRetriever(vectorstore, embedding_manager)\n",
    "rag_retriever\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3676c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for the 'what is tnskill registry '\n",
      "Top K : 5, score threshold : 0.0\n",
      "Generating embeddings for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filetring)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_5761f1bc_2',\n",
       "  'content': '\\uf0b7 \\nPublish after Admin Approval. \\n\\uf0b7 \\nView responses and engagement directly from the dashboard. \\nTNSkill Registry Manual \\nIndustry / Company /Employer Registration and Login \\nStep 1: \\nOpen your browser, enter naanmudhalvan.tn.gov.in in the address bar, and click on \\nTNSkill Registry Button (as highlighted in the image below). \\n \\nStep 2: \\nClick on “Register” button (as highlighted in the image below).',\n",
       "  'metadata': {'source': '../data/Manual for Skill registry - Industry Registration and Login.pdf',\n",
       "   'total_pages': 17,\n",
       "   'file_type': 'pdf',\n",
       "   'modDate': 'D:20250923092952Z',\n",
       "   'doc_index': 2,\n",
       "   'trapped': '',\n",
       "   'format': 'PDF 1.5',\n",
       "   'content_length': 403,\n",
       "   'author': 'AVP-Portal Naanmudhalvan',\n",
       "   'page': 1,\n",
       "   'creationDate': \"D:20250923092952+00'00'\",\n",
       "   'moddate': '2025-09-23T09:29:52+00:00',\n",
       "   'creationdate': '2025-09-23T09:29:52+00:00',\n",
       "   'file_path': '../data/Manual for Skill registry - Industry Registration and Login.pdf',\n",
       "   'keywords': '',\n",
       "   'title': '',\n",
       "   'source_file': 'Manual for Skill registry - Industry Registration and Login.pdf',\n",
       "   'subject': '',\n",
       "   'creator': 'Microsoft® Word 2016',\n",
       "   'producer': 'www.ilovepdf.com'},\n",
       "  'similarity_score': 0.23710322380065918,\n",
       "  'distance': 0.7628967761993408,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_147dc900_0',\n",
       "  'content': 'Key Features of TNSKILL Registry \\n1. Simple Registration & Login \\n\\uf0b7 \\nRegister using Company / Industry details with admin approval \\nprocess. \\n\\uf0b7 \\nMultiple login methods: Email/Password, Mobile/Password, OTP (Email \\n/ Mobile). \\n2. AI-Powered Search for Skilled Professionals \\n\\uf0b7 \\nText Search: Enter skills/requirements directly. \\n\\uf0b7 \\nVoice Search: Search in English or Tamil with microphone support. \\n\\uf0b7 \\nManual Search: Apply filters such as Branch, District, Year of Passing, \\nCollege Type, Gender, Placement Status, etc. \\n3. Detailed Candidate Profiles \\n\\uf0b7 \\nView Name, Skills, Qualifications, Experience, Resume, Certification \\ndetails, Location, Current Status, and more. \\n\\uf0b7 \\nApply filters in real time (Gender, District, College Type, etc.) for \\nrefined results. \\n4. Shortlisting & Invites \\n\\uf0b7 \\nShortlist multiple candidates. \\n\\uf0b7 \\nSend interview invites via Email, WhatsApp, or SMS. \\n\\uf0b7 \\nCandidates can Accept or Reject invitations. \\n5. Invite & Offer Management \\n\\uf0b7',\n",
       "  'metadata': {'source': '../data/Manual for Skill registry - Industry Registration and Login.pdf',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'author': 'AVP-Portal Naanmudhalvan',\n",
       "   'file_path': '../data/Manual for Skill registry - Industry Registration and Login.pdf',\n",
       "   'source_file': 'Manual for Skill registry - Industry Registration and Login.pdf',\n",
       "   'subject': '',\n",
       "   'trapped': '',\n",
       "   'title': '',\n",
       "   'moddate': '2025-09-23T09:29:52+00:00',\n",
       "   'creationdate': '2025-09-23T09:29:52+00:00',\n",
       "   'format': 'PDF 1.5',\n",
       "   'doc_index': 0,\n",
       "   'total_pages': 17,\n",
       "   'modDate': 'D:20250923092952Z',\n",
       "   'creationDate': \"D:20250923092952+00'00'\",\n",
       "   'creator': 'Microsoft® Word 2016',\n",
       "   'content_length': 960,\n",
       "   'keywords': '',\n",
       "   'file_type': 'pdf',\n",
       "   'page': 0},\n",
       "  'similarity_score': 0.19399118423461914,\n",
       "  'distance': 0.8060088157653809,\n",
       "  'rank': 2}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"what is tnskill registry \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59eac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0f268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
